{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".mode()\n",
    ".median()\n",
    ".mean() # of each columns\n",
    ".mean(axis=1) # of each row\n",
    "max(df[\"\"]) - min(df[\"\"]) # Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-98005ec63c0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/train.csv', index_col=0) # specify index_col=0 to avoid creating an \"Unnamed: 0\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_series = pd.Series( data = [2,3,5,4],             # Data\n",
    "                       index= ['a', 'b', 'c', 'd'])  # Indexes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(my_dict)   # Convert the dict to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The probability of seeing a result as extreme or more extreme than the one observed is known as the p-value.\n",
    "\n",
    "The T Test is a statistical test used to determine whether a numeric data sample of differs significantly from the population or whether two samples differ from one another.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't know the standard deviation of the population, you have to use the standard deviation of your sample as a stand in when creating confidence intervals. Since the sample standard deviation may not match the population parameter the interval will have more error when you don't know the population standard deviation. To account for this error, we use what's known as a t-critical value instead of the z-critical value. The t-critical value is drawn from what's known as a t-distribution--a distribution that closely resembles the normal distribution but that gets wider and wider as the sample size falls. The t-distribution is available in scipy.stats with the nickname \"t\" so we can get t-critical values with stats.t.ppf()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a large sample, the t-critical value will approach the z-critical value so there is little difference between using the normal distribution vs. the t-distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, alpha(ùõº) is set to 0.05, which has as a side-effect that there is a 5 percent chance that you will reject the null hypothesis when it is true.\n",
    "###### \"with a confidence level of 95%, we can state that...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Sample T Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checks whether a sample mean differs from the population mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "To conduct a one sample t-test, we can the stats.ttest_1samp() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_1samp(a= minnesota_ages,                 # sample data\n",
    "                 popmean= population_ages.mean())    # population mean\n",
    "\n",
    "# this will provide t-statistic in first element and p value in the second\n",
    "# p value tells you the probability that you'll see a result as extreme as the one observed due to chance\n",
    "# in other words we would only expect to see a difference between these two as large as observed here due \n",
    "# to chance about \"p-value\" amounts of time\n",
    "# this is where statistical significance levels comes in, if we want a 95% confidence that we wont accept the \n",
    "# alternative hypothesis when it isnt actually true -- then we want to see a p value that is .05 % or less berfore we\n",
    "# are willing to say ok that is strong evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.ppf(q=0.025, # Quantile to check/ test statistic \"t\" #(.5 split in half between top and bottom tails)\n",
    "            df=49)   # Degrees of freedom\n",
    "# degrees of freedom is size of our sample minus 1\n",
    "# run opposit side to get upper quartile\n",
    "stats.t.ppf(q=0.975, # Quantile to check/ test statistic \"t\" #(.5 split in half between top and bottom tails)\n",
    "            df=49)   # Degrees of freedom\n",
    "# the re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the chances of seeing a result as extreme as the one we observed (known as the p-value) by passing the t-statistic in as the quantile to the stats.t.cdf() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.cdf(x= -2.5742,      # T-test statistic\n",
    "               df= 49) * 2   # Multiply by two for two tailed test *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to construct a 95% confidence interval for the sample it would not capture population mean of 43:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = minnesota_ages.std()/math.sqrt(50)  # Sample stdev/sample size\n",
    "\n",
    "stats.t.interval(0.95,                        # Confidence level\n",
    "                 df = 49,                     # Degrees of freedom\n",
    "                 loc = minnesota_ages.mean(), # Sample mean\n",
    "                 scale= sigma)   \n",
    "# output: (36.369669080722176, 42.15033091927782)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, since there is a 1.3% chance of seeing a result this extreme due to chance, it is not significant at the 99% confidence level. This means if we were to construct a 99% confidence interval, it would capture the population mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.interval(alpha = 0.99,                # Confidence level\n",
    "                 df = 49,                     # Degrees of freedom\n",
    "                 loc = minnesota_ages.mean(), # Sample mean\n",
    "                 scale= sigma)                # Standard dev estimate\n",
    "# output: (35.40547994092107, 43.11452005907893)\n",
    "\n",
    "# With a higher confidence level, we construct a wider confidence interval and increase the chances that it captures \n",
    "# to true mean, thus making it less likely that we'll reject the null hypothesis. \n",
    "# In this case, the p-value of 0.013 is greater than our significance level of 0.01 and we fail to reject the null \n",
    "# hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two-Sample T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigates whether the means of two independent data samples differ from one another. In a two-sample test, the null hypothesis is that the means of both groups are the same. Unlike the one sample-test where we test against a known population parameter, the two sample test only involves sample means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "You can conduct a two-sample t-test by passing with the stats.ttest_ind() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(a= minnesota_ages,\n",
    "                b= wisconsin_ages,\n",
    "                equal_var=False)    # Assume samples have equal variance?\n",
    "# output: Ttest_indResult(statistic=-1.7083870793286842, pvalue=0.09073104343957748)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paired T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing differences between independent groups. In some cases, you might be interested in testing differences between samples of the same group at different points in time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can conduct a paired t-test using the scipy function stats.ttest_rel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_rel(a = before,\n",
    "                b = after)\n",
    "# output: Ttest_relResult(statistic=2.5720175998568284, pvalue=0.011596444318439857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type I and Type II Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type I error describes a situation where you reject the null hypothesis when it is actually true. This type of error is also known as a \"false positive\" or \"false hit\". \n",
    "The type 1 error rate is equal to the significance level Œ±, so setting a higher confidence level (and therefore lower alpha) reduces the chances of getting a false positive.\n",
    "\n",
    "Type II error describes a situation where you fail to reject the null hypothesis when it is actually false. Type II error is also known as a \"false negative\" or \"miss\". \n",
    "The higher your confidence level, the more likely you are to make a type II error. You might misass actual differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Sample z-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performed when the population means and standard deviation are known\n",
    "# best suited for situations where you want to investigate\n",
    "# whether a given \"sample\" comes from a particular \"population\"\n",
    "# alternative hypothesis ( ùêªùëé ): sample mean is significantly bigger/less than the population mean\n",
    "# null hypothesis ( ùêª0 ): no significant difference between the sample mean and population mean\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from math import sqrt\n",
    "x_bar = 103 # sample mean \n",
    "n = 40 # number of students\n",
    "sigma = 16 # sd of population\n",
    "mu = 100 # Population mean \n",
    "\n",
    "z = (x_bar - mu)/(sigma/sqrt(n))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ùëß -value on a standard normal distribution to see what it means\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.fill_between(x=np.arange(-4,1.19,0.01),\n",
    "                 y1= stats.norm.pdf(np.arange(-4,1.19,0.01)) ,\n",
    "                 facecolor='red',\n",
    "                 alpha=0.35,\n",
    "                 label= 'Area below z-statistic'\n",
    "                 )\n",
    "\n",
    "plt.fill_between(x=np.arange(1.19,4,0.01), \n",
    "                 y1= stats.norm.pdf(np.arange(1.19,4,0.01)) ,\n",
    "                 facecolor='blue',\n",
    "                 alpha=0.35, \n",
    "                 label= 'Area above z-statistic')\n",
    "plt.legend()\n",
    "plt.title ('z-statistic = 1.19');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is a method used to define a relationship between a dependent variable (Y) and independent variable (X). Which is simply written as :\n",
    "\n",
    "y = mx + b\n",
    "Where y is the dependent variable, m is the scale factor or coefficient, b being the bias coefficient and X being the independent variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLS Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top half\n",
    "r square and adj r square\n",
    "r square will increase with more features addded, adj r square will accounts for it by penalizing r squared values that include non-useful predictors. If there is large difference between r squared and adj r squared you likely have non relevant features, those should be found and omitted.\n",
    "The coefficient of determination that is denoted by r-squared is the proportion of variance in the dependent variable that is predicatable from the independent variable. If regression model fits very well then you will have an R squared value closer to 1.\n",
    "It is a misconceotion that r-sqaured cannot be negative, if you fail to practice best practices you can end up w a big negative number\n",
    "\n",
    "f statistic or f test\n",
    "is used for assessing the significance of the overall regression model. in multiple regression, it compares the model with no predictor, so a intercept only model, only intercept values. \n",
    "prob (f-statistic)\n",
    "this p value and the f statistic value that will help chose whether to reject or accept the null hypothesis. If low p value and f statistic between 1 and high, we can reject the null, there is a good amount of linear relationship between my target variable and my feature variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bottom half\n",
    "in order to infer if a feature is significant or relevant to the target we perform a t test. slightly diff than f test. it looks at the relationship between the target variable and every predictor variable indeoendently without taking into account all the features at once. it goes one feature at a time, so you will have a t test perform between feature 1 and target column, then  feature 2 and target column and so forth. null is feature 1 value is going to be zero and alt is that it is that the feature coefficient value is not zero. you also get the associated p value. \n",
    "t values and associated p values with the higher the t value the greater the chances that you reject the null hypothesis and you accept the alternative hypothesis \n",
    "p value: lower p value signifies that you again reject the null hypothesis. If all features have a p value of zero, you reject the null hypothesis, stating that the weight values of these particular features are non-zero.\n",
    "\n",
    "If coefficient if negative, that can be okay, but if its t value is very small and on top of that the p value is very high, we would say that particular feature is irrelevant to our model and we can drop it and not use it later on to make a prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "variance\n",
    "variance measures the dispersion of a set of data points around their mean value. \n",
    "population variance, sigma squared, is equal to the sum of squared differences between the observed values and the population mean, divided by the total number of observations \n",
    "sample variance, s squared, equal to the sum of squared differences between observed sample values and the sample mean, divided by the number of sample observations minus 1. can be alrge and hard to compare since it is squared. quick fix is standard daviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "standard deviation\n",
    "easy fix to variance is to calculate its square root and obtain a statistic, known as the standard deviation, which can be more meaningful than variance. their formulas are square root of the population variance/sample variance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coefficient of variation\n",
    "is equal to the standard deviation divided by the mean. also known as the relative standard deviation. its formula is standard deviation relative to the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "comparing the stand daeviations od two or more different data sets is meaningless, but comparing coefficients of variation is not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Part 1: Normal Distribution [Suggested time: 20 minutes]¬∂\n",
    "In this part, you will analyze check totals at a TexMex restaurant. We know that the population distribution of check totals for the TexMex restaurant is normally distributed with a mean of $20 and a standard deviation of $3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
